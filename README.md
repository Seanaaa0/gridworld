# ðŸ§  GridWorld: Reinforcement Learning Playground

This project implements a customizable GridWorld environment for training RL agents using tabular reinforcement learning methods like Q-learning and SARSA.

It supports variable grid sizes, deterministic transitions, goal and pit placement, and visual rendering of the agentâ€™s behavior.

---

## ðŸš€ Features

- âœ… 10x10 and NxN grid environments  
- âœ… Deterministic transition system (up/down/left/right)  
- âœ… Q-learning and SARSA training support  
- âœ… CLI: supports alpha, gamma, epsilon, episodes  
- âœ… Visualization of agent behavior and learned path  
- âœ… Save/load Q-table in `.npy` format  

---

## ðŸ“‚ Folder Structure

```
grid/
â”œâ”€â”€ envs/                 # GridEnv10x10 / GridEnvNxN classes
â”œâ”€â”€ run/                  # Training and evaluation scripts
â”œâ”€â”€ outputs/              # Q-table files and training results
â”œâ”€â”€ visual/               # (Optional) rendering helper functions
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## ðŸ’» Quick Start

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Train on 10x10 grid

```bash
python run/run_10x10_cli.py --episodes 3000 --alpha 0.1 --gamma 0.9 --epsilon 0.1 --render
```

---

## ðŸ§  Use Case

This project serves as:

- An educational sandbox for tabular RL algorithms  
- A training data generator for future GPT-based planning systems  
- A reproducible environment for debugging policies in grid-based navigation tasks

---

## ðŸ”® Future Work

- Train GPT model to predict best action/goal based on partial trajectories  
- Integrate offline RL dataset and convert to `jsonl` for fine-tuning  
- Add support for non-deterministic transitions and partial observability

---

## ðŸ‘¤ Author

Developed by [@Seanaaa0](https://github.com/Seanaaa0)  
Self-directed AI engineer focused on RL, LLM fine-tuning, and agent design.
